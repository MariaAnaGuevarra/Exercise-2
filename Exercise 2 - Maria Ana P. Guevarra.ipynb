{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6897ea1",
   "metadata": {},
   "source": [
    "# Exercise 2 - Maria Ana P. Guevarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413144c",
   "metadata": {},
   "source": [
    "### Load the Browns corpus from NLTK (nltk.corpus.brown) with fiction category (pass the category to the loader functions). From the corpus, load the tagged and untagged sentences. Make sure that the tags are using the universal tag set. \n",
    "\n",
    "### To evaluate the taggers, divide the tagged sentence into 75-25 split for training tagging algorithms and testing them.Report both the accuracy on the training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca314e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('book',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac46759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nltk.corpus.brown.sents()\n",
    "fiction = nltk.corpus.brown.tagged_sents(categories='fiction',tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71130bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(fiction)*0.75)\n",
    "train = fiction[:split]\n",
    "test = fiction[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a55928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged:  [('He', 'PRON'), ('had', 'VERB'), ('not', 'ADV'), ('felt', 'VERB'), ('that', 'ADP'), ('during', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('.', '.')]\n",
      "Untagged:  ['He', 'had', 'not', 'felt', 'that', 'during', 'the', 'afternoon', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "test_sent = untag(test[0])\n",
    "print(\"Tagged: \",test[0])\n",
    "print(\"Untagged: \",test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9cf0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training data:  0.6%\n",
      "Accuracy on the testing data:  0.8%\n"
     ]
    }
   ],
   "source": [
    "from nltk import DefaultTagger\n",
    "print(\"Accuracy on the training data: %4.1f%%\" % (100.0 * DefaultTagger('NUM').evaluate(train)))\n",
    "print(\"Accuracy on the testing data: %4.1f%%\" % (100.0 * DefaultTagger('NUM').evaluate(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8efd2",
   "metadata": {},
   "source": [
    "### Submit the notebook that performs the tasks below.\n",
    "\n",
    "### 1.\tExplore the performance of N-Gram taggers on the corpus. \n",
    "### a.\tUnigram Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589890e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.tag.UnigramTagger(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0118ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438119069961422"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ab76b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'),\n",
       "  ('Fulton', None),\n",
       "  ('County', 'NOUN'),\n",
       "  ('Grand', None),\n",
       "  ('Jury', None),\n",
       "  ('said', 'VERB'),\n",
       "  ('Friday', 'NOUN'),\n",
       "  ('an', 'DET'),\n",
       "  ('investigation', None),\n",
       "  ('of', 'ADP'),\n",
       "  (\"Atlanta's\", None),\n",
       "  ('recent', None),\n",
       "  ('primary', None),\n",
       "  ('election', None),\n",
       "  ('produced', 'VERB'),\n",
       "  ('``', '.'),\n",
       "  ('no', 'DET'),\n",
       "  ('evidence', None),\n",
       "  (\"''\", '.'),\n",
       "  ('that', 'ADP'),\n",
       "  ('any', 'DET'),\n",
       "  ('irregularities', None),\n",
       "  ('took', 'VERB'),\n",
       "  ('place', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('jury', None),\n",
       "  ('further', 'ADV'),\n",
       "  ('said', 'VERB'),\n",
       "  ('in', 'ADP'),\n",
       "  ('term-end', None),\n",
       "  ('presentments', None),\n",
       "  ('that', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('City', 'NOUN'),\n",
       "  ('Executive', None),\n",
       "  ('Committee', None),\n",
       "  (',', '.'),\n",
       "  ('which', 'DET'),\n",
       "  ('had', 'VERB'),\n",
       "  ('over-all', 'ADJ'),\n",
       "  ('charge', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('election', None),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('deserves', None),\n",
       "  ('the', 'DET'),\n",
       "  ('praise', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('thanks', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('City', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('Atlanta', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('manner', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('which', 'DET'),\n",
       "  ('the', 'DET'),\n",
       "  ('election', None),\n",
       "  ('was', 'VERB'),\n",
       "  ('conducted', 'VERB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('September-October', None),\n",
       "  ('term', 'NOUN'),\n",
       "  ('jury', None),\n",
       "  ('had', 'VERB'),\n",
       "  ('been', 'VERB'),\n",
       "  ('charged', 'VERB'),\n",
       "  ('by', 'ADP'),\n",
       "  ('Fulton', None),\n",
       "  ('Superior', None),\n",
       "  ('Court', None),\n",
       "  ('Judge', None),\n",
       "  ('Durwood', None),\n",
       "  ('Pye', None),\n",
       "  ('to', 'PRT'),\n",
       "  ('investigate', None),\n",
       "  ('reports', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('possible', 'ADJ'),\n",
       "  ('``', '.'),\n",
       "  ('irregularities', None),\n",
       "  (\"''\", '.'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('hard-fought', None),\n",
       "  ('primary', None),\n",
       "  ('which', 'DET'),\n",
       "  ('was', 'VERB'),\n",
       "  ('won', 'VERB'),\n",
       "  ('by', 'ADP'),\n",
       "  ('Mayor-nominate', None),\n",
       "  ('Ivan', None),\n",
       "  ('Allen', 'NOUN'),\n",
       "  ('Jr.', None),\n",
       "  ('.', '.')],\n",
       " [('``', '.'),\n",
       "  ('Only', 'ADV'),\n",
       "  ('a', 'DET'),\n",
       "  ('relative', None),\n",
       "  ('handful', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('such', 'PRT'),\n",
       "  ('reports', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('received', 'VERB'),\n",
       "  (\"''\", '.'),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('jury', None),\n",
       "  ('said', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('``', '.'),\n",
       "  ('considering', None),\n",
       "  ('the', 'DET'),\n",
       "  ('widespread', None),\n",
       "  ('interest', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('election', None),\n",
       "  (',', '.'),\n",
       "  ('the', 'DET'),\n",
       "  ('number', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('voters', None),\n",
       "  ('and', 'CONJ'),\n",
       "  ('the', 'DET'),\n",
       "  ('size', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('this', 'DET'),\n",
       "  ('city', 'NOUN'),\n",
       "  (\"''\", '.'),\n",
       "  ('.', '.')],\n",
       " [('The', 'DET'),\n",
       "  ('jury', None),\n",
       "  ('said', 'VERB'),\n",
       "  ('it', 'PRON'),\n",
       "  ('did', 'VERB'),\n",
       "  ('find', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  ('many', 'ADJ'),\n",
       "  ('of', 'ADP'),\n",
       "  (\"Georgia's\", None),\n",
       "  ('registration', None),\n",
       "  ('and', 'CONJ'),\n",
       "  ('election', None),\n",
       "  ('laws', 'NOUN'),\n",
       "  ('``', '.'),\n",
       "  ('are', 'VERB'),\n",
       "  ('outmoded', None),\n",
       "  ('or', 'CONJ'),\n",
       "  ('inadequate', None),\n",
       "  ('and', 'CONJ'),\n",
       "  ('often', 'ADV'),\n",
       "  ('ambiguous', None),\n",
       "  (\"''\", '.'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag_sents(data)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001da64",
   "metadata": {},
   "source": [
    "### b.\tUnigram Tagger with a verb backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8bb3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.tag.DefaultTagger('VERB')\n",
    "unigram_tagger_backoff = nltk.tag.UnigramTagger(train, backoff=default_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d99f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633715977771468"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger_backoff.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "953aef55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678448545511417"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger_backoff.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e505e7e",
   "metadata": {},
   "source": [
    "### c.\tTrigram Tagger with Unigram Tagger and adjective backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24cdc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.tag.DefaultTagger('ADJ')\n",
    "unigram_tagger = nltk.tag.UnigramTagger(train)\n",
    "trigram_tagger_backoff = nltk.tag.TrigramTagger(train,backoff=default_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b94cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9177382063034925"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger_backoff.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fcd2faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4365551037430925"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger_backoff.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198db09",
   "metadata": {},
   "source": [
    "### d.\tTrigram Tagger with a Bigram Tagger backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e992e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.tag.BigramTagger(train)\n",
    "trigram_tagger_backoff = nltk.tag.UnigramTagger(train, backoff=bigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "832f37c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9340242566827567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger_backoff.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8755323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4915545824210197"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tagger_backoff.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29242284",
   "metadata": {},
   "source": [
    "### 2.\tTrain an Average Perceptron Tagger with different iterations. Compare the results of using different iterations.\n",
    "### a.\t1 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac609a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained.train(train,nr_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219f50e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591327627469274"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cc44c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283182149932229"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b5289",
   "metadata": {},
   "source": [
    "### b.\t5 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0827f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained.train(train,nr_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dc5eddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9951324382428102"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99323462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94906683348973"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a362893",
   "metadata": {},
   "source": [
    "### c.\t10 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d94521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained.train(train,nr_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1286fa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990264876485621"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "586adfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9524032947554999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_trained.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc14e5c",
   "metadata": {},
   "source": [
    "## Based on the data above, more iterations produce much more accurate result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115ccf",
   "metadata": {},
   "source": [
    "### Train a 3 Conditional Random Field using a different custom feature function. The feature function must contain the features below. Model A should use features a-c. Model B should use features a-e and Model C should use all the features.\n",
    "\n",
    "### a. Previous, Current, and Next Word\n",
    "### b. 1-3 Character Prefix\n",
    "### c. 1-3 Character Suffix\n",
    "### d. Capitalize\n",
    "### e. Word contains a number\n",
    "### f. Word is first in the sentence\n",
    "### g. Word is last in the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ce8a1",
   "metadata": {},
   "source": [
    "### Model A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd295047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelA_features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f42d26da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crf_custom_A = nltk.crf.CRFTagger(feature_func=modelA_features)\n",
    "crf_custom_A.train(train,'crf_custom_A.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c8386f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9786232912830082\n"
     ]
    }
   ],
   "source": [
    "crf_modelA_train = crf_custom_A.evaluate(train)\n",
    "print(\"Training data accuracy: \", crf_modelA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcababf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516213116463351\n"
     ]
    }
   ],
   "source": [
    "crf_modelA_test = crf_custom_A.evaluate(test)\n",
    "print(\"Testing data accuracy: \", crf_modelA_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85003c8",
   "metadata": {},
   "source": [
    "### Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adbeb25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelB_features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "   \n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        \n",
    "\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        \n",
    "   \n",
    "        'is_numeric': sentence[index].isdigit()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "531540d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_custom_B = nltk.crf.CRFTagger(feature_func=modelB_features)\n",
    "crf_custom_B.train(train, 'crf_custom_B.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57434415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9785827282683649\n"
     ]
    }
   ],
   "source": [
    "crf_modelB_train = crf_custom_B.evaluate(train)\n",
    "print(\"Training data accuracy: \", crf_modelB_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87ec28ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516734438536127\n"
     ]
    }
   ],
   "source": [
    "crf_modelB_test = crf_custom_B.evaluate(test)\n",
    "print(\"Testing data accuracy: \", crf_modelB_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6b669",
   "metadata": {},
   "source": [
    "### Model C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f37f7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelC_features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "    \n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        \n",
    " \n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        \n",
    " \n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        \n",
    "\n",
    "        'is_first': index == 0,\n",
    "        \n",
    "\n",
    "        'is_last': index == len(sentence) - 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "713741de",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_custom_C = nltk.crf.CRFTagger(feature_func=modelC_features)\n",
    "crf_custom_C.train(train, 'crf_custom_C.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f68b083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9785421652537216\n"
     ]
    }
   ],
   "source": [
    "crf_modelC_train = crf_custom_C.evaluate(train)\n",
    "print(\"Training data accuracy: \", crf_modelC_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cb39c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516734438536127\n"
     ]
    }
   ],
   "source": [
    "crf_modelC_test = crf_custom_C.evaluate(test)\n",
    "print(\"Testing data accuracy: \", crf_modelC_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
